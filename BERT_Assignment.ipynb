{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aUl8AXidsJ8SARj4nE23qbKBBv6gaYdB",
      "authorship_tag": "ABX9TyMhCxzp71YeLWPYMzJHWPLS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GauravSahani1417/BERT-Implementation/blob/master/BERT_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFwCQTkjKoxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "outputId": "4789584c-298d-4a27-dc71-0f36395a515c"
      },
      "source": [
        "!pip install tensorflow==1.15\n",
        "!pip install tensorflow_hub==0.7.0"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.31.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (49.2.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: tensorflow_hub==0.7.0 in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub==0.7.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub==0.7.0) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub==0.7.0) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow_hub==0.7.0) (49.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPHxTPRUK3Uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbmcDzA1LUUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c66cb39c-f824-49d4-e2df-91eee2392dca"
      },
      "source": [
        "print(\"tensorflow version : \", tf.__version__)\n",
        "print(\"tensorflow_hub version : \", hub.__version__)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensorflow version :  1.15.0\n",
            "tensorflow_hub version :  0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFPflTZgLnpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ypdHif0LukY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "86f97663-f894-4d62-d633-6d3233c87ffe"
      },
      "source": [
        "#Installing BERT module\n",
        "!pip install bert-tensorflow==1.0.1"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow==1.0.1 in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow==1.0.1) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92QdlXI1LyHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67AdFG_xL04w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8e25db7-7598-49d2-84e7-b1235643c2aa"
      },
      "source": [
        "OUTPUT_DIR = '/content/drive/My Drive/BERT'\n",
        "\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = False #@param {type:\"boolean\"}\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: /content/drive/My Drive/BERT *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3It_nlPCF3q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_excel(\"/content/drive/My Drive/BERT/Data_Train.xlsx\")\n",
        "test = pd.read_excel(\"/content/drive/My Drive/BERT/Data_Test.xlsx\")\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, val =  train_test_split(train, test_size = 0.21, random_state = 100)\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YKAOmy3C16s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "76467538-1224-4b09-e47c-d5f7036f6bfc"
      },
      "source": [
        "train.head(5)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STORY</th>\n",
              "      <th>SECTION</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1517</th>\n",
              "      <td>The Galaxy M20 is priced at ₹12,990 for the 4G...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5976</th>\n",
              "      <td>The flight to safety is spurring sell-offs in ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6371</th>\n",
              "      <td>New Delhi: Bharti Airtel today launched a new ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3557</th>\n",
              "      <td>Android's next major update tentatively named ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5205</th>\n",
              "      <td>The stellar growth saw India uprooting the US ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  STORY  SECTION\n",
              "1517  The Galaxy M20 is priced at ₹12,990 for the 4G...        1\n",
              "5976  The flight to safety is spurring sell-offs in ...        3\n",
              "6371  New Delhi: Bharti Airtel today launched a new ...        1\n",
              "3557  Android's next major update tentatively named ...        1\n",
              "5205  The stellar growth saw India uprooting the US ...        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q06Ii4nHC6bz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "e66a2ecf-f52b-4590-f990-57ff9fa4665a"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STORY</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019 will see gadgets like gaming smartphones ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It has also unleashed a wave of changes in the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It can be confusing to pick the right smartpho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The mobile application is integrated with a da...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>We have rounded up some of the gadgets that sh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               STORY\n",
              "0  2019 will see gadgets like gaming smartphones ...\n",
              "1  It has also unleashed a wave of changes in the...\n",
              "2  It can be confusing to pick the right smartpho...\n",
              "3  The mobile application is integrated with a da...\n",
              "4  We have rounded up some of the gadgets that sh..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoEw5RL9DTeK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7f8a829a-3e97-4a61-8ba2-9697252288b6"
      },
      "source": [
        "print(\"Training Set Shape :\", train.shape)\n",
        "print(\"Validation Set Shape :\", val.shape)\n",
        "print(\"Test Set Shape :\", test.shape)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Shape : (6026, 2)\n",
            "Validation Set Shape : (1602, 2)\n",
            "Test Set Shape : (2748, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpy5ZVqCDX2r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8b6fc84-4136-46ed-e098-02172030872c"
      },
      "source": [
        "train.columns"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['STORY', 'SECTION'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayV-YvwIDbQQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7a0a58c-8645-4515-a829-42ef835de7e9"
      },
      "source": [
        "train['SECTION'].unique()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 0, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TxXHWFhDd0A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "dee46fca-3cb6-4f4e-f824-a51e70723dfa"
      },
      "source": [
        "#Distribution of classes\n",
        "train['SECTION'].value_counts().plot(kind = 'bar')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faca85f5b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeC8FK36DhcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'STORY'\n",
        "LABEL_COLUMN = 'SECTION'\n",
        "label_list = [0, 1, 2, 3]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aIplsQgDpXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "val_InputExamples = val.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaA6t1RaD4Dz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "39e1df73-bcc2-4b98-89b6-a1c85880a350"
      },
      "source": [
        "train_InputExamples"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1517    <bert.run_classifier.InputExample object at 0x...\n",
              "5976    <bert.run_classifier.InputExample object at 0x...\n",
              "6371    <bert.run_classifier.InputExample object at 0x...\n",
              "3557    <bert.run_classifier.InputExample object at 0x...\n",
              "5205    <bert.run_classifier.InputExample object at 0x...\n",
              "                              ...                        \n",
              "79      <bert.run_classifier.InputExample object at 0x...\n",
              "3927    <bert.run_classifier.InputExample object at 0x...\n",
              "5955    <bert.run_classifier.InputExample object at 0x...\n",
              "6936    <bert.run_classifier.InputExample object at 0x...\n",
              "5640    <bert.run_classifier.InputExample object at 0x...\n",
              "Length: 6026, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1IswbhxD1O_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "da4509af-bd1a-42ac-ae45-6495a84efe42"
      },
      "source": [
        "val_InputExamples"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "564     <bert.run_classifier.InputExample object at 0x...\n",
              "2909    <bert.run_classifier.InputExample object at 0x...\n",
              "4146    <bert.run_classifier.InputExample object at 0x...\n",
              "5312    <bert.run_classifier.InputExample object at 0x...\n",
              "5022    <bert.run_classifier.InputExample object at 0x...\n",
              "                              ...                        \n",
              "5160    <bert.run_classifier.InputExample object at 0x...\n",
              "420     <bert.run_classifier.InputExample object at 0x...\n",
              "3684    <bert.run_classifier.InputExample object at 0x...\n",
              "4568    <bert.run_classifier.InputExample object at 0x...\n",
              "4117    <bert.run_classifier.InputExample object at 0x...\n",
              "Length: 1602, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4-nAaWrI7u2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "b9f8bbfb-41b2-4f22-f6c5-f080f8b74b3d"
      },
      "source": [
        "print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n",
        "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n",
        "print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n",
        "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Row 0 - guid of training set :  None\n",
            "\n",
            "__________\n",
            "Row 0 - text_a of training set :  The Galaxy M20 is priced at ₹12,990 for the 4GB+64GB variant while the 3GB+32GB variant costs ₹10,990.\n",
            "\n",
            "\n",
            "Both the devices were a complete sell-out on Amazon India on February 5, making an \"unprecedented\" first-day sale record for the Korean tech giant.\n",
            "\n",
            "__________\n",
            "Row 0 - text_b of training set :  None\n",
            "\n",
            "__________\n",
            "Row 0 - label of training set :  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf22qnqxEKNq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3ab35b6d-f80b-4638-c8b4-0aee6d007503"
      },
      "source": [
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kVdb-55HwkO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "89ea1a4f-ca0c-4060-edff-68fdf3397b0e"
      },
      "source": [
        "#Here is what the tokenised sample of the first training set observation looks like\n",
        "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'galaxy', 'm2', '##0', 'is', 'priced', 'at', '₹', '##12', ',', '99', '##0', 'for', 'the', '4', '##gb', '+', '64', '##gb', 'variant', 'while', 'the', '3', '##gb', '+', '32', '##gb', 'variant', 'costs', '₹', '##10', ',', '99', '##0', '.', 'both', 'the', 'devices', 'were', 'a', 'complete', 'sell', '-', 'out', 'on', 'amazon', 'india', 'on', 'february', '5', ',', 'making', 'an', '\"', 'unprecedented', '\"', 'first', '-', 'day', 'sale', 'record', 'for', 'the', 'korean', 'tech', 'giant', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nT601iJeEknR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e5da5a66-9925-4651-cc03-76ea483b3d7b"
      },
      "source": [
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "# Convert our train and validation features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 6026\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 6026\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the galaxy m2 ##0 is priced at ₹ ##12 , 99 ##0 for the 4 ##gb + 64 ##gb variant while the 3 ##gb + 32 ##gb variant costs ₹ ##10 , 99 ##0 . both the devices were a complete sell - out on amazon india on february 5 , making an \" unprecedented \" first - day sale record for the korean tech giant . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the galaxy m2 ##0 is priced at ₹ ##12 , 99 ##0 for the 4 ##gb + 64 ##gb variant while the 3 ##gb + 32 ##gb variant costs ₹ ##10 , 99 ##0 . both the devices were a complete sell - out on amazon india on february 5 , making an \" unprecedented \" first - day sale record for the korean tech giant . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 9088 25525 2692 2003 21125 2012 1576 12521 1010 5585 2692 2005 1996 1018 18259 1009 4185 18259 8349 2096 1996 1017 18259 1009 3590 18259 8349 5366 1576 10790 1010 5585 2692 1012 2119 1996 5733 2020 1037 3143 5271 1011 2041 2006 9733 2634 2006 2337 1019 1010 2437 2019 1000 15741 1000 2034 1011 2154 5096 2501 2005 1996 4759 6627 5016 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 9088 25525 2692 2003 21125 2012 1576 12521 1010 5585 2692 2005 1996 1018 18259 1009 4185 18259 8349 2096 1996 1017 18259 1009 3590 18259 8349 5366 1576 10790 1010 5585 2692 1012 2119 1996 5733 2020 1037 3143 5271 1011 2041 2006 9733 2634 2006 2337 1019 1010 2437 2019 1000 15741 1000 2034 1011 2154 5096 2501 2005 1996 4759 6627 5016 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the flight to safety is spur ##ring sell - offs in some parts of emerging asia . yields on indonesian debt due in 10 years climbed five basis points to 7 . 66 percent as investors ditch high - beta assets . the inverted yield curve in the world ’ s biggest bond market is sending a negative signal for developing - nation assets , according to win thin , global head of currency strategy at brown brothers ha ##rri ##man & co . in new york . “ if sustained , it would signal a likely u . s . recession in the next six to 24 months , \" he said . “ this is hardly con ##du ##ci ##ve to risk and em [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the flight to safety is spur ##ring sell - offs in some parts of emerging asia . yields on indonesian debt due in 10 years climbed five basis points to 7 . 66 percent as investors ditch high - beta assets . the inverted yield curve in the world ’ s biggest bond market is sending a negative signal for developing - nation assets , according to win thin , global head of currency strategy at brown brothers ha ##rri ##man & co . in new york . “ if sustained , it would signal a likely u . s . recession in the next six to 24 months , \" he said . “ this is hardly con ##du ##ci ##ve to risk and em [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 3462 2000 3808 2003 12996 4892 5271 1011 12446 1999 2070 3033 1997 8361 4021 1012 16189 2006 9003 7016 2349 1999 2184 2086 6589 2274 3978 2685 2000 1021 1012 5764 3867 2004 9387 14033 2152 1011 8247 7045 1012 1996 20037 10750 7774 1999 1996 2088 1521 1055 5221 5416 3006 2003 6016 1037 4997 4742 2005 4975 1011 3842 7045 1010 2429 2000 2663 4857 1010 3795 2132 1997 9598 5656 2012 2829 3428 5292 18752 2386 1004 2522 1012 1999 2047 2259 1012 1523 2065 8760 1010 2009 2052 4742 1037 3497 1057 1012 1055 1012 19396 1999 1996 2279 2416 2000 2484 2706 1010 1000 2002 2056 1012 1523 2023 2003 6684 9530 8566 6895 3726 2000 3891 1998 7861 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 3462 2000 3808 2003 12996 4892 5271 1011 12446 1999 2070 3033 1997 8361 4021 1012 16189 2006 9003 7016 2349 1999 2184 2086 6589 2274 3978 2685 2000 1021 1012 5764 3867 2004 9387 14033 2152 1011 8247 7045 1012 1996 20037 10750 7774 1999 1996 2088 1521 1055 5221 5416 3006 2003 6016 1037 4997 4742 2005 4975 1011 3842 7045 1010 2429 2000 2663 4857 1010 3795 2132 1997 9598 5656 2012 2829 3428 5292 18752 2386 1004 2522 1012 1999 2047 2259 1012 1523 2065 8760 1010 2009 2052 4742 1037 3497 1057 1012 1055 1012 19396 1999 1996 2279 2416 2000 2484 2706 1010 1000 2002 2056 1012 1523 2023 2003 6684 9530 8566 6895 3726 2000 3891 1998 7861 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] new delhi : b ##hart ##i air ##tel today launched a new app — air ##tel books . with this , air ##tel has further diversified its fast - growing digital content portfolio to add to its popular offerings like w ##yn ##k music and air ##tel tv . available to both air ##tel and non - air ##tel customers in ios and android , air ##tel books will initially offer over 70 , 000 titles from indian and international authors . air ##tel says it plans to rapidly expand its e - books collection by partnering with leading publishers as well as lever ##aging its strategic partnership with jug ##ger ##naut books . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] new delhi : b ##hart ##i air ##tel today launched a new app — air ##tel books . with this , air ##tel has further diversified its fast - growing digital content portfolio to add to its popular offerings like w ##yn ##k music and air ##tel tv . available to both air ##tel and non - air ##tel customers in ios and android , air ##tel books will initially offer over 70 , 000 titles from indian and international authors . air ##tel says it plans to rapidly expand its e - books collection by partnering with leading publishers as well as lever ##aging its strategic partnership with jug ##ger ##naut books . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2047 6768 1024 1038 10686 2072 2250 9834 2651 3390 1037 2047 10439 1517 2250 9834 2808 1012 2007 2023 1010 2250 9834 2038 2582 24908 2049 3435 1011 3652 3617 4180 11103 2000 5587 2000 2049 2759 14927 2066 1059 6038 2243 2189 1998 2250 9834 2694 1012 2800 2000 2119 2250 9834 1998 2512 1011 2250 9834 6304 1999 16380 1998 11924 1010 2250 9834 2808 2097 3322 3749 2058 3963 1010 2199 4486 2013 2796 1998 2248 6048 1012 2250 9834 2758 2009 3488 2000 5901 7818 2049 1041 1011 2808 3074 2011 27001 2007 2877 8544 2004 2092 2004 15929 16594 2049 6143 5386 2007 26536 4590 24619 2808 1012 102 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2047 6768 1024 1038 10686 2072 2250 9834 2651 3390 1037 2047 10439 1517 2250 9834 2808 1012 2007 2023 1010 2250 9834 2038 2582 24908 2049 3435 1011 3652 3617 4180 11103 2000 5587 2000 2049 2759 14927 2066 1059 6038 2243 2189 1998 2250 9834 2694 1012 2800 2000 2119 2250 9834 1998 2512 1011 2250 9834 6304 1999 16380 1998 11924 1010 2250 9834 2808 2097 3322 3749 2058 3963 1010 2199 4486 2013 2796 1998 2248 6048 1012 2250 9834 2758 2009 3488 2000 5901 7818 2049 1041 1011 2808 3074 2011 27001 2007 2877 8544 2004 2092 2004 15929 16594 2049 6143 5386 2007 26536 4590 24619 2808 1012 102 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] android ' s next major update tentatively named \" q \" could see the removal of the back button and a quicker app - changing animation when users sw ##ipe to the right . \" most of the complaints that people have towards android pie ' s gestures focus on the presence of the dedicated back button and the difficulty of performing the long sw ##ipe up of the pill to open the app drawer . while i don ' t know if the latter gesture will be changed in android q , there ' s a really good chance that google may kill the dedicated back button , \" x ##da developers reported on monday . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] android ' s next major update tentatively named \" q \" could see the removal of the back button and a quicker app - changing animation when users sw ##ipe to the right . \" most of the complaints that people have towards android pie ' s gestures focus on the presence of the dedicated back button and the difficulty of performing the long sw ##ipe up of the pill to open the app drawer . while i don ' t know if the latter gesture will be changed in android q , there ' s a really good chance that google may kill the dedicated back button , \" x ##da developers reported on monday . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11924 1005 1055 2279 2350 10651 19325 2315 1000 1053 1000 2071 2156 1996 8208 1997 1996 2067 6462 1998 1037 19059 10439 1011 5278 7284 2043 5198 25430 15457 2000 1996 2157 1012 1000 2087 1997 1996 10821 2008 2111 2031 2875 11924 11345 1005 1055 18327 3579 2006 1996 3739 1997 1996 4056 2067 6462 1998 1996 7669 1997 4488 1996 2146 25430 15457 2039 1997 1996 17357 2000 2330 1996 10439 13065 1012 2096 1045 2123 1005 1056 2113 2065 1996 3732 9218 2097 2022 2904 1999 11924 1053 1010 2045 1005 1055 1037 2428 2204 3382 2008 8224 2089 3102 1996 4056 2067 6462 1010 1000 1060 2850 9797 2988 2006 6928 1012 102 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 11924 1005 1055 2279 2350 10651 19325 2315 1000 1053 1000 2071 2156 1996 8208 1997 1996 2067 6462 1998 1037 19059 10439 1011 5278 7284 2043 5198 25430 15457 2000 1996 2157 1012 1000 2087 1997 1996 10821 2008 2111 2031 2875 11924 11345 1005 1055 18327 3579 2006 1996 3739 1997 1996 4056 2067 6462 1998 1996 7669 1997 4488 1996 2146 25430 15457 2039 1997 1996 17357 2000 2330 1996 10439 13065 1012 2096 1045 2123 1005 1056 2113 2065 1996 3732 9218 2097 2022 2904 1999 11924 1053 1010 2045 1005 1055 1037 2428 2204 3382 2008 8224 2089 3102 1996 4056 2067 6462 1010 1000 1060 2850 9797 2988 2006 6928 1012 102 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the stellar growth saw india up ##ro ##oting the us as the world ’ s second largest mobile phone market by volume - - ranking behind china but hands ##et prices have been sk ##ew ##ed towards lower - end of the market . “ this is likely to change fast . we expect that mid - range smartphone ##s , those with wholesale prices in the range of $ 200 - 400 , will grow 20 per cent year - on - year in 2018 and by almost four times during the next five years to make it one of the most important smartphone segments , \" counter ##point research associate director tar ##un path ##ak told pt ##i . he said the sales volume [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] the stellar growth saw india up ##ro ##oting the us as the world ’ s second largest mobile phone market by volume - - ranking behind china but hands ##et prices have been sk ##ew ##ed towards lower - end of the market . “ this is likely to change fast . we expect that mid - range smartphone ##s , those with wholesale prices in the range of $ 200 - 400 , will grow 20 per cent year - on - year in 2018 and by almost four times during the next five years to make it one of the most important smartphone segments , \" counter ##point research associate director tar ##un path ##ak told pt ##i . he said the sales volume [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 17227 3930 2387 2634 2039 3217 20656 1996 2149 2004 1996 2088 1521 1055 2117 2922 4684 3042 3006 2011 3872 1011 1011 5464 2369 2859 2021 2398 3388 7597 2031 2042 15315 7974 2098 2875 2896 1011 2203 1997 1996 3006 1012 1523 2023 2003 3497 2000 2689 3435 1012 2057 5987 2008 3054 1011 2846 26381 2015 1010 2216 2007 17264 7597 1999 1996 2846 1997 1002 3263 1011 4278 1010 2097 4982 2322 2566 9358 2095 1011 2006 1011 2095 1999 2760 1998 2011 2471 2176 2335 2076 1996 2279 2274 2086 2000 2191 2009 2028 1997 1996 2087 2590 26381 9214 1010 1000 4675 8400 2470 5482 2472 16985 4609 4130 4817 2409 13866 2072 1012 2002 2056 1996 4341 3872 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1996 17227 3930 2387 2634 2039 3217 20656 1996 2149 2004 1996 2088 1521 1055 2117 2922 4684 3042 3006 2011 3872 1011 1011 5464 2369 2859 2021 2398 3388 7597 2031 2042 15315 7974 2098 2875 2896 1011 2203 1997 1996 3006 1012 1523 2023 2003 3497 2000 2689 3435 1012 2057 5987 2008 3054 1011 2846 26381 2015 1010 2216 2007 17264 7597 1999 1996 2846 1997 1002 3263 1011 4278 1010 2097 4982 2322 2566 9358 2095 1011 2006 1011 2095 1999 2760 1998 2011 2471 2176 2335 2076 1996 2279 2274 2086 2000 2191 2009 2028 1997 1996 2087 2590 26381 9214 1010 1000 4675 8400 2470 5482 2472 16985 4609 4130 4817 2409 13866 2072 1012 2002 2056 1996 4341 3872 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 1602\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 1602\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] traders said , reduced demand from local jewel ##lers as well as retail buyers led to the slide in gold prices . in the international market , spot gold was trading at usd 1 , 299 . 30 an ounce while silver was at usd 15 . 31 an ounce in new york . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] traders said , reduced demand from local jewel ##lers as well as retail buyers led to the slide in gold prices . in the international market , spot gold was trading at usd 1 , 299 . 30 an ounce while silver was at usd 15 . 31 an ounce in new york . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 13066 2056 1010 4359 5157 2013 2334 13713 12910 2004 2092 2004 7027 17394 2419 2000 1996 7358 1999 2751 7597 1012 1999 1996 2248 3006 1010 3962 2751 2001 6202 2012 13751 1015 1010 25926 1012 2382 2019 19471 2096 3165 2001 2012 13751 2321 1012 2861 2019 19471 1999 2047 2259 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 13066 2056 1010 4359 5157 2013 2334 13713 12910 2004 2092 2004 7027 17394 2419 2000 1996 7358 1999 2751 7597 1012 1999 1996 2248 3006 1010 3962 2751 2001 6202 2012 13751 1015 1010 25926 1012 2382 2019 19471 2096 3165 2001 2012 13751 2321 1012 2861 2019 19471 1999 2047 2259 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 3 (id = 3)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] a recent amazon job posting , seeking a quality assurance manager for alexa data services in bucharest , describes the role humans play : “ every day she [ alexa ] listen ##s to thousands of people talking to her about different topics and different languages , and she needs our help to make sense of it all . \" the want ad continues : “ this is big data handling like you ’ ve never seen it . we ’ re creating , labeling , cu ##rating and analyzing vast quantities of speech on a daily basis . \" amazon ’ s review process for speech data begins when alexa pulls a random , small sampling of customer voice recordings and sends the audio files [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] a recent amazon job posting , seeking a quality assurance manager for alexa data services in bucharest , describes the role humans play : “ every day she [ alexa ] listen ##s to thousands of people talking to her about different topics and different languages , and she needs our help to make sense of it all . \" the want ad continues : “ this is big data handling like you ’ ve never seen it . we ’ re creating , labeling , cu ##rating and analyzing vast quantities of speech on a daily basis . \" amazon ’ s review process for speech data begins when alexa pulls a random , small sampling of customer voice recordings and sends the audio files [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1037 3522 9733 3105 14739 1010 6224 1037 3737 16375 3208 2005 24969 2951 2578 1999 14261 1010 5577 1996 2535 4286 2377 1024 1523 2296 2154 2016 1031 24969 1033 4952 2015 2000 5190 1997 2111 3331 2000 2014 2055 2367 7832 1998 2367 4155 1010 1998 2016 3791 2256 2393 2000 2191 3168 1997 2009 2035 1012 1000 1996 2215 4748 4247 1024 1523 2023 2003 2502 2951 8304 2066 2017 1521 2310 2196 2464 2009 1012 2057 1521 2128 4526 1010 28847 1010 12731 15172 1998 20253 6565 12450 1997 4613 2006 1037 3679 3978 1012 1000 9733 1521 1055 3319 2832 2005 4613 2951 4269 2043 24969 8005 1037 6721 1010 2235 16227 1997 8013 2376 5633 1998 10255 1996 5746 6764 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1037 3522 9733 3105 14739 1010 6224 1037 3737 16375 3208 2005 24969 2951 2578 1999 14261 1010 5577 1996 2535 4286 2377 1024 1523 2296 2154 2016 1031 24969 1033 4952 2015 2000 5190 1997 2111 3331 2000 2014 2055 2367 7832 1998 2367 4155 1010 1998 2016 3791 2256 2393 2000 2191 3168 1997 2009 2035 1012 1000 1996 2215 4748 4247 1024 1523 2023 2003 2502 2951 8304 2066 2017 1521 2310 2196 2464 2009 1012 2057 1521 2128 4526 1010 28847 1010 12731 15172 1998 20253 6565 12450 1997 4613 2006 1037 3679 3978 1012 1000 9733 1521 1055 3319 2832 2005 4613 2951 4269 2043 24969 8005 1037 6721 1010 2235 16227 1997 8013 2376 5633 1998 10255 1996 5746 6764 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] new delhi : the bharatiya janata party manifesto monday promised to increase intake capacity of central engineering , management , science and law institutions by 50 % over the next five years if voted to power but remains silent on the impending new education policy . central institutions encompass indian institutes of technology ( ii ##ts ) , indian institute of management ( ii ##ms ) , all indian institutions of medical science ( ai ##im ##s ) , national law universities , indian institute of science technology and research ( ii ##ser ) among others . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] new delhi : the bharatiya janata party manifesto monday promised to increase intake capacity of central engineering , management , science and law institutions by 50 % over the next five years if voted to power but remains silent on the impending new education policy . central institutions encompass indian institutes of technology ( ii ##ts ) , indian institute of management ( ii ##ms ) , all indian institutions of medical science ( ai ##im ##s ) , national law universities , indian institute of science technology and research ( ii ##ser ) among others . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2047 6768 1024 1996 24243 20308 2283 17124 6928 5763 2000 3623 13822 3977 1997 2430 3330 1010 2968 1010 2671 1998 2375 4896 2011 2753 1003 2058 1996 2279 2274 2086 2065 5444 2000 2373 2021 3464 4333 2006 1996 17945 2047 2495 3343 1012 2430 4896 25281 2796 12769 1997 2974 1006 2462 3215 1007 1010 2796 2820 1997 2968 1006 2462 5244 1007 1010 2035 2796 4896 1997 2966 2671 1006 9932 5714 2015 1007 1010 2120 2375 5534 1010 2796 2820 1997 2671 2974 1998 2470 1006 2462 8043 1007 2426 2500 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2047 6768 1024 1996 24243 20308 2283 17124 6928 5763 2000 3623 13822 3977 1997 2430 3330 1010 2968 1010 2671 1998 2375 4896 2011 2753 1003 2058 1996 2279 2274 2086 2065 5444 2000 2373 2021 3464 4333 2006 1996 17945 2047 2495 3343 1012 2430 4896 25281 2796 12769 1997 2974 1006 2462 3215 1007 1010 2796 2820 1997 2968 1006 2462 5244 1007 1010 2035 2796 4896 1997 2966 2671 1006 9932 5714 2015 1007 1010 2120 2375 5534 1010 2796 2820 1997 2671 2974 1998 2470 1006 2462 8043 1007 2426 2500 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] facebook declined to comment , while what ##sa ##pp and ins ##tagram did not immediately respond to a request for comment . the panel has previously summoned social network twitter inc ' s chief executive jack dorsey to appear on monday to discuss the same topic . \" these are issues for all internet services globally , \" twitter said on friday , adding that colin crowe ##ll , its global vice president of public policy , is to meet the panel on monday . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] facebook declined to comment , while what ##sa ##pp and ins ##tagram did not immediately respond to a request for comment . the panel has previously summoned social network twitter inc ' s chief executive jack dorsey to appear on monday to discuss the same topic . \" these are issues for all internet services globally , \" twitter said on friday , adding that colin crowe ##ll , its global vice president of public policy , is to meet the panel on monday . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 9130 6430 2000 7615 1010 2096 2054 3736 9397 1998 16021 23091 2106 2025 3202 6869 2000 1037 5227 2005 7615 1012 1996 5997 2038 3130 11908 2591 2897 10474 4297 1005 1055 2708 3237 2990 27332 2000 3711 2006 6928 2000 6848 1996 2168 8476 1012 1000 2122 2024 3314 2005 2035 4274 2578 16452 1010 1000 10474 2056 2006 5958 1010 5815 2008 6972 25657 3363 1010 2049 3795 3580 2343 1997 2270 3343 1010 2003 2000 3113 1996 5997 2006 6928 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 9130 6430 2000 7615 1010 2096 2054 3736 9397 1998 16021 23091 2106 2025 3202 6869 2000 1037 5227 2005 7615 1012 1996 5997 2038 3130 11908 2591 2897 10474 4297 1005 1055 2708 3237 2990 27332 2000 3711 2006 6928 2000 6848 1996 2168 8476 1012 1000 2122 2024 3314 2005 2035 4274 2578 16452 1010 1000 10474 2056 2006 5958 1010 5815 2008 6972 25657 3363 1010 2049 3795 3580 2343 1997 2270 3343 1010 2003 2000 3113 1996 5997 2006 6928 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] “ in my home , i often communicate in both english and hindi . so i ’ m very excited about this feature that lets me use the assistant in a more natural way , \" said gupta . google india ##and ##roid goa ##nd ##roid go pie ##sam ##sun ##g galaxy j ##2 core ##no ##kia ##lav ##ami ##cr ##oma ##x ##go ##og ##le assistant ##go ##og ##le assistant marathi ##go ##og ##le go ##ma ##ps go [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] “ in my home , i often communicate in both english and hindi . so i ’ m very excited about this feature that lets me use the assistant in a more natural way , \" said gupta . google india ##and ##roid goa ##nd ##roid go pie ##sam ##sun ##g galaxy j ##2 core ##no ##kia ##lav ##ami ##cr ##oma ##x ##go ##og ##le assistant ##go ##og ##le assistant marathi ##go ##og ##le go ##ma ##ps go [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1523 1999 2026 2188 1010 1045 2411 10639 1999 2119 2394 1998 9269 1012 2061 1045 1521 1049 2200 7568 2055 2023 3444 2008 11082 2033 2224 1996 3353 1999 1037 2062 3019 2126 1010 1000 2056 20512 1012 8224 2634 5685 22943 15244 4859 22943 2175 11345 21559 19729 2290 9088 1046 2475 4563 3630 21128 14973 10631 26775 9626 2595 3995 8649 2571 3353 3995 8649 2571 3353 18388 3995 8649 2571 2175 2863 4523 2175 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1523 1999 2026 2188 1010 1045 2411 10639 1999 2119 2394 1998 9269 1012 2061 1045 1521 1049 2200 7568 2055 2023 3444 2008 11082 2033 2224 1996 3353 1999 1037 2062 3019 2126 1010 1000 2056 20512 1012 8224 2634 5685 22943 15244 4859 22943 2175 11345 21559 19729 2290 9088 1046 2475 4563 3630 21128 14973 10631 26775 9626 2595 3995 8649 2571 3353 3995 8649 2571 3353 18388 3995 8649 2571 2175 2863 4523 2175 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdjJfuEfHc0x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "2d1b41d8-3e46-4c4f-a3e2-3e7d67c097d2"
      },
      "source": [
        "print(\"Sentence : \", train_InputExamples.iloc[0].text_a)\n",
        "print(\"-\"*30)\n",
        "print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n",
        "print(\"-\"*30)\n",
        "print(\"Input IDs : \", train_features[0].input_ids)\n",
        "print(\"-\"*30)\n",
        "print(\"Input Masks : \", train_features[0].input_mask)\n",
        "print(\"-\"*30)\n",
        "print(\"Segment IDs : \", train_features[0].segment_ids)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence :  The Galaxy M20 is priced at ₹12,990 for the 4GB+64GB variant while the 3GB+32GB variant costs ₹10,990.\n",
            "\n",
            "\n",
            "Both the devices were a complete sell-out on Amazon India on February 5, making an \"unprecedented\" first-day sale record for the Korean tech giant.\n",
            "------------------------------\n",
            "Tokens :  ['the', 'galaxy', 'm2', '##0', 'is', 'priced', 'at', '₹', '##12', ',', '99', '##0', 'for', 'the', '4', '##gb', '+', '64', '##gb', 'variant', 'while', 'the', '3', '##gb', '+', '32', '##gb', 'variant', 'costs', '₹', '##10', ',', '99', '##0', '.', 'both', 'the', 'devices', 'were', 'a', 'complete', 'sell', '-', 'out', 'on', 'amazon', 'india', 'on', 'february', '5', ',', 'making', 'an', '\"', 'unprecedented', '\"', 'first', '-', 'day', 'sale', 'record', 'for', 'the', 'korean', 'tech', 'giant', '.']\n",
            "------------------------------\n",
            "Input IDs :  [101, 1996, 9088, 25525, 2692, 2003, 21125, 2012, 1576, 12521, 1010, 5585, 2692, 2005, 1996, 1018, 18259, 1009, 4185, 18259, 8349, 2096, 1996, 1017, 18259, 1009, 3590, 18259, 8349, 5366, 1576, 10790, 1010, 5585, 2692, 1012, 2119, 1996, 5733, 2020, 1037, 3143, 5271, 1011, 2041, 2006, 9733, 2634, 2006, 2337, 1019, 1010, 2437, 2019, 1000, 15741, 1000, 2034, 1011, 2154, 5096, 2501, 2005, 1996, 4759, 6627, 5016, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "------------------------------\n",
            "Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "------------------------------\n",
            "Segment IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I460vbcHLn60",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5XOA1JyMN4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#A function that adapts our model to work for training, evaluation, and prediction.\n",
        "\n",
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        \n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "            }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhaflwA_MVZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 30\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 300\n",
        "SAVE_SUMMARY_STEPS = 100\n",
        "\n",
        "# Compute train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7BRuWO3MiND",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "6c7621bc-9fc9-4e34-94ce-e726bf08474a"
      },
      "source": [
        "#Initializing the model and the estimator\n",
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/content/drive/My Drive/BERT', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7facb4a126a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/content/drive/My Drive/BERT', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7facb4a126a0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrEl8sSFMnQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)\n",
        "\n",
        "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
        "val_input_fn = run_classifier.input_fn_builder(\n",
        "    features=val_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qo8FZCVMqtR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 692
        },
        "outputId": "8f689950-d322-4c6d-f943-6fbe8ec20644"
      },
      "source": [
        "#Training the model\n",
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/BERT/model.ckpt-0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /content/drive/My Drive/BERT/model.ckpt-0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /content/drive/My Drive/BERT/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /content/drive/My Drive/BERT/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.5102636, step = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 1.5102636, step = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1 vs previous value: 1. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1 vs previous value: 1. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3 vs previous value: 3. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3 vs previous value: 3. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 6 vs previous value: 6. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 6 vs previous value: 6. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10 vs previous value: 10. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10 vs previous value: 10. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 13 vs previous value: 13. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 13 vs previous value: 13. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FjIRyvQgsxj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Evaluating the model with Validation set\n",
        "estimator.evaluate(input_fn=val_input_fn, steps=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np0fxDDvPoZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"Politics: 0\n",
        "Technology: 1\n",
        "Entertainment: 2\n",
        "Business: 3\"\"\"\n",
        "\n",
        "# A method to get predictions\n",
        "def getPrediction(in_sentences):\n",
        "  #A list to map the actual labels to the predictions\n",
        "  labels = [\"Politics\", \"Technology\",\"Entertainment\",\"Business\"]\n",
        "\n",
        "  #Transforming the test data into BERT accepted form\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n",
        "  \n",
        "  #Creating input features for Test data\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "  #Predicting the classes \n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities'],prediction['labels'], labels[prediction['labels']]) for sentence, prediction in zip(in_sentences, predictions)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtDAtnflT-G9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_sentences = list(test['STORY'])\n",
        "\n",
        "predictions = getPrediction(pred_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP0kIQsOUHDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubj0kjgZUIJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}